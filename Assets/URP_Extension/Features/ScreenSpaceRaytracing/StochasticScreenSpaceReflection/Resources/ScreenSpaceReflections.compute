// Definitions
//--------------------------------------------------------------------------------------------------

// TODO: delete
#pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch

#pragma kernel ScreenSpaceReflectionsClassifyTiles
#pragma kernel ScreenSpaceReflectionsTracing
// #pragma kernel ScreenSpaceReflectionsResolve                                                SSR_RESOLVE
// #pragma kernel ScreenSpaceReflectionsAccumulate                                             SSR_ACCUMULATE

#pragma multi_compile _ SSR_APPROX
#pragma multi_compile _ _GBUFFER_NORMALS_OCT
#pragma multi_compile _ _GPU_LIGHTS_CLUSTER

// Tweak parameters.
#define SSR_TRACE_BEHIND_OBJECTS
#define SSR_TRACE_TOWARDS_EYE

#define SSR_TRACE_EPS               0.000488281f // 2^-11, should be good up to 4K
#define MIN_GGX_ROUGHNESS           0.00001f
#define MAX_GGX_ROUGHNESS           0.99999f
//--------------------------------------------------------------------------------------------------
// Included headers
//--------------------------------------------------------------------------------------------------
#define TILE_INDEX_SHIFT_X (0)
#define TILE_INDEX_SHIFT_Y (15)
#define TILE_INDEX_MASK (32767)

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/ImageBasedLighting.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/UnityGBuffer.hlsl"
#include "ScreenSpaceLighting.hlsl"
#include "../ShaderVariablesScreenSpaceReflection.cs.hlsl"

#include "ImportantSample.hlsl"
// #ifdef SSR_TRACE
// #include "Packages/com.unity.render-pipelines.danbaidong/ShaderLibrary/GPUCulledLights.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/GlobalIllumination.hlsl"
// #endif

//--------------------------------------------------------------------------------------------------
// Inputs & outputs
//--------------------------------------------------------------------------------------------------

// Global Textures
TEXTURE2D_X_FLOAT(_CameraDepthTexture);
SAMPLER(sampler_CameraDepthTexture);

TEXTURE2D_X(_ColorPyramidTexture);

TEXTURE2D(_CameraDepthPyramidTexture);
// StructuredBuffer<int2> _DepthPyramidMipLevelOffsets;

TEXTURE2D_X_FLOAT(_GBuffer2);

SAMPLER(ssr_trilinear_clamp_sampler);
SAMPLER(ssr_bilinear_clamp_sampler);
SAMPLER(ssr_point_clamp_sampler);


// Indirect dispatch args
RWBuffer<uint> gDispatchIndirectBuffer;
RWStructuredBuffer<uint> gTileList;

TEXTURECUBE(_SkyTexture);

//SSR_TRACE
RW_TEXTURE2D(float4, _RayHitColorTexture);
RW_TEXTURE2D(float3, _SSRRayInfoTexture);


// PerPass Input & outputs
#ifdef SSR_CLASSIFYTILES
#elif defined(SSR_TRACE)
    RW_TEXTURE2D(float4, _RayHitColorTexture);
    RW_TEXTURE2D(float3, _SSRRayInfoTexture);
#elif defined(SSR_RESOLVE)
    // _CameraDepthTexture
    // _GBuffer2
    RW_TEXTURE2D(float3, _SSRRayInfoTexture);
       TEXTURE2D(        _RayHitColorTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
    RW_TEXTURE2D(float3, _SSRAvgRadianceTexture);
#elif defined(SSR_ACCUMULATE)
    // _CameraDepthTexture
    // _GBuffer2
       TEXTURE2D(        _SSRRayInfoTexture);
       TEXTURE2D(        _SsrAccumPrev);
       TEXTURE2D(        _SSRAvgRadianceTexture);
       TEXTURE2D(        _SSRPrevNumFramesAccumTexture);
    RW_TEXTURE2D(float4, _SsrLightingTexture);
    RW_TEXTURE2D(float4, _SSRAccumTexture);
    RW_TEXTURE2D(float,  _SSRNumFramesAccumTexture);
#endif
// We also have bilateral and a-trous path in git history, but they have poor performance.

// Use constant buffer instead


//--------------------------------------------------------------------------------------------------
// Helpers
//--------------------------------------------------------------------------------------------------

#define NEED_RAYTRACED_REFLECTIONS(perceptualRoughness) (perceptualRoughness < _SsrRoughnessFadeEnd)
#define IS_MIRROR_REFLECTIONS(perceptualRoughness) (perceptualRoughness < 0.01)

uint2 DecodeTileIndex(uint encoded)
{
    return uint2((encoded >> TILE_INDEX_SHIFT_X) & TILE_INDEX_MASK, (encoded >> TILE_INDEX_SHIFT_Y) & TILE_INDEX_MASK);
}

uint EncodeTileIndex(uint2 tileID)
{
    return (tileID.y << TILE_INDEX_SHIFT_Y) | (tileID.x << TILE_INDEX_SHIFT_X);
}

void InitializeDispatchThreadIdFromTileList(uint groupId, uint2 gThreadId, out uint2 dThreadId)
{
    uint encodedTileIndex = gTileList[groupId];
    uint2 tileCoord = DecodeTileIndex(encodedTileIndex);
    dThreadId = tileCoord + gThreadId.xy;
}

float2 TransformCoordSSToScreenUV(uint2 coordSS, float4 screenSize)
{
    return coordSS * screenSize.zw + (0.5 * screenSize.zw);
}

uint2 TransformScreenUVToCoordSS(float2 screenUV, float4 screenSize)
{
    uint2 coordSS = screenUV / screenSize.zw;
    coordSS = floor(coordSS);
    return coordSS;
}

// Weight for SSR where Fresnel == 1
float GetSSRSampleWeight(float NdotV, float NdotL, float roughness)
{
    // Importance sampling weight for each sample:
    // pdf = G1(V) * D(H) / (4 * (N.V));
    // weight = fr * (N.L) with fr = F(H) * G2(V, L) * D(H) / (4 * (N.L) * (N.V))
    // weight over pdf is:
    // weightOverPdf = F(H) * G2(V, L) / G1(V)
    // F is apply outside the function

    // V = G / (4 * NdotL * NdotV)
    float G2 = V_SmithJointGGX(NdotL, NdotV, roughness) * 4 * NdotL * NdotV;
    float G1 = G_MaskingSmithGGX(NdotV, roughness);

    return G2 / G1;
}

float PerceptualRoughnessFade(float perceptualRoughness, float fadeRcpLength, float fadeEndTimesRcpLength)
{
    float t = Remap10(perceptualRoughness, fadeRcpLength, fadeEndTimesRcpLength);
    return Smoothstep01(t);
}

void LoadNormalAndPerceptualRoughness(uint2 coordSS, out float3 normalWS, out float perceptualRoughness)
{
    // Load normal and perceptualRoughness.
    float4 normalGBuffer = LOAD_TEXTURE2D_X(_GBuffer2, coordSS);

    normalWS = normalize(UnpackNormal(normalGBuffer.xyz));
    // normalize() is required because terrain shaders use additive blending for normals (not unit-length anymore)
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalGBuffer.a);
}

void SampleNormalAndPerceptualRoughness(float2 screenUV, out float3 normalWS, out float perceptualRoughness)
{
    // Load normal and perceptualRoughness.
    float4 normalGBuffer = SAMPLE_TEXTURE2D_X_LOD(_GBuffer2, ssr_point_clamp_sampler, screenUV, 0);

    normalWS = normalize(UnpackNormal(normalGBuffer.xyz));
    // normalize() is required because terrain shaders use additive blending for normals (not unit-length anymore)
    perceptualRoughness = PerceptualSmoothnessToPerceptualRoughness(normalGBuffer.a);
}

float3 SampleRadianceFromPrevColorPyramid(float2 hitScreenUV)
{
    float3 radiance = 0;

    float mipLevel = 0;
    // MotionVector, colorPyramid is from last frame.
    float2 motionVectorOff = SampleMotionVectorOffset(hitScreenUV, _ScreenSize);
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_trilinear_clamp_sampler, prevFrameUV, mipLevel).rgb;

    return radiance;
}

float3 LoadUVAndSampleRadianceFromPrevColorPyramid(float2 hitScreenUV)
{
    float3 radiance = 0;

    // MotionVector, colorPyramid is from last frame.
    // TODO: resolve motion vector reprojection error
    float2 motionVectorOff = LoadMotionVectorOffset(TransformScreenUVToCoordSS(hitScreenUV, _ScreenSize));
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    // mipLevel is 0 so we use bilinear
    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_bilinear_clamp_sampler, prevFrameUV, 0).rgb;

    return radiance;
}

float4 LoadUVAndSampleRadianceFromPrevColorPyramidWithOpacity(float2 hitScreenUV)
{
    float3 radiance = 0;

    // MotionVector, colorPyramid is from last frame.
    // TODO: resolve motion vector reprojection error
    float2 motionVectorOff = LoadMotionVectorOffset(TransformScreenUVToCoordSS(hitScreenUV, _ScreenSize));
    float2 prevFrameNDC = hitScreenUV - motionVectorOff;
    float2 prevFrameUV = prevFrameNDC * _ColorPyramidUvScaleAndLimitPrevFrame.xy;

    // mipLevel is 0 so we use bilinear
    radiance = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, ssr_bilinear_clamp_sampler, prevFrameUV, 0).rgb;

    float edgeOpacity = EdgeOfScreenFade(prevFrameNDC, _SsrEdgeFadeRcpLength);

    return float4(radiance, edgeOpacity);
}

//https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Weighted_incremental_algorithm
void IncreaseVariance(float weight, float x, inout float weightSum, inout float mean, inout float varianceSum)
{
    weightSum += weight;
    float meanOld = mean;
    mean += (weight / weightSum) * (x - meanOld);
    varianceSum += weight * (x - meanOld) * (x - mean);
}

// See LinearEyeDepth()
// zBufferParam = { (f-n)/n, 1, (f-n)/n*f, 1/f }
float LinearDepthToDeviceZ(float linearDepth, float4 zBufferParam)
{
    return ((1.0 / linearDepth) - zBufferParam.w) / zBufferParam.z;
}


float CalculateLocalBrdfWeight(float3 N, float3 V, float3 L, float roughness)
{
    float3 H = normalize(V + L);
    float NdotH = dot(N, H);
    float NdotL = dot(N, L);
    float NdotV = dot(N, V);

    return DV_SmithJointGGX(NdotH, saturate(NdotL), ClampNdotV(NdotV), roughness);
}


// Ray Tracing rays coord buffer
#define RAY_COORD_MASK (0xffffu)
#define RAY_COORD_SHIFT_X (0)
#define RAY_COORD_SHIFT_Y (16)

uint2 DecodeRayCoord(uint encoded)
{
    return uint2((encoded >> RAY_COORD_SHIFT_X) & RAY_COORD_MASK, (encoded >> RAY_COORD_SHIFT_Y) & RAY_COORD_MASK);
}

uint EncodeRayCoord(uint2 tileID)
{
    return (tileID.y << RAY_COORD_SHIFT_Y) | (tileID.x << RAY_COORD_SHIFT_X);
}

float4 SampleSkyTexture(float3 texCoord, float lod, int sliceIndex = 0)
{
    return SAMPLE_TEXTURECUBE_LOD(_SkyTexture, sampler_TrilinearClamp, texCoord, lod);
}

float3 SampleSkyEnvironment(float3 reflectVector, float perceptualRoughness)
{
    float mip = PerceptualRoughnessToMipmapLevel(perceptualRoughness);
    return SampleSkyTexture(reflectVector, mip).rgb;
}



//--------------------------------------------------------------------------------------------------
// Implementation
//--------------------------------------------------------------------------------------------------


groupshared uint gTileCount = 0;

[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsClassifyTiles(uint3 dispatchThreadId : SV_DispatchThreadID,
                                         uint2 groupThreadId : SV_GroupThreadID)
{
    uint2 coordSS = dispatchThreadId.xy;
    float3 N;
    float perceptualRoughness;

    // Disable offscreen pixels
    float2 coordSSFloat = float2(coordSS);
    bool needsRay = !(coordSSFloat.x >= _ScreenSize.x || coordSSFloat.y >= _ScreenSize.y);

    // Don't shoot a ray on very rough surfaces depends on _SsrRoughnessFadeEnd.
    LoadNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
    needsRay = needsRay && NEED_RAYTRACED_REFLECTIONS(perceptualRoughness);

    // Don't shoot a ray on sky.
    float deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
    needsRay = needsRay && !(deviceDepth == UNITY_RAW_FAR_CLIP_VALUE);


    if (needsRay)
    {
        InterlockedAdd(gTileCount, 1);
    }

    GroupMemoryBarrierWithGroupSync();


    if ((groupThreadId.x == 0) && (groupThreadId.y == 0) && (gTileCount > 0))
    {
        uint tileOffset = 0;
        InterlockedAdd(gDispatchIndirectBuffer[0], 1, tileOffset);
        gTileList[tileOffset] = EncodeTileIndex(dispatchThreadId.xy);
    }
}


[numthreads(8, 8, 1)]
void ScreenSpaceReflectionsTracing(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID,
                                   uint groupId : SV_GroupID)
{
    uint2 coordSS;
    InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);

    float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);

    float deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;

    if (deviceDepth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        // Sky early return;
        // _SSRRayInfoTexture[coordSS] = 0;
        return;
    }

    float3 N;
    float perceptualRoughness;
    LoadNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
    float oneOverPDF = 0.0f;

    if (!NEED_RAYTRACED_REFLECTIONS(perceptualRoughness))
    {
        // No need reflection.
        // _SSRRayInfoTexture[coordSS] = 0;
        return;
    }


    float3 positionWS = ComputeWorldSpacePosition(screenUV, deviceDepth, UNITY_MATRIX_I_VP); // Jittered
    float3 V = GetWorldSpaceNormalizeViewDir(positionWS);

    float3 originPosWS = positionWS;

    float ConeAngle = 0.0f;
    float3 R = reflect(-V, N); //default
    #ifdef SSR_APPROX

    #else
    // PBR
    if (perceptualRoughness > 0.0001f)
    {
        float2 blueNoiseRandom = 0;
        blueNoiseRandom.xy = GetSpatiotemporalBlueNoiseVec2(coordSS);

        float NdotL, VdotH, NdotV;
        float3x3 localToWorld = GetLocalFrame(N);
        float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
        roughness = lerp(roughness, 0.0f, _SsrPBRBias);
        roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);

        float3 localV, localH;
        SampleGGXVisibleNormalSphericalCaps(blueNoiseRandom, V, localToWorld, roughness, localV, localH, VdotH);
        float rayPDF = VisibleGGXPDF(localV, localH, roughness);
        float3 worldH = mul(localH, localToWorld);
        R = roughness == 0 ? R : reflect(-V, worldH);
        NdotL = dot(N, R);
        NdotV = dot(N, V);

        ConeAngle = 1.0f / max(rayPDF, 0.0001f);
    }

    #endif /* SSR_PBR */

    float3 camPosWS = GetCurrentViewPosition();

    // Apply normal bias with the magnitude dependent on the distance from the camera.
    // Unfortunately, we only have access to the shading normal, which is less than ideal...
    positionWS = camPosWS + (positionWS - camPosWS) * (1 - 0.001 * rcp(max(dot(N, V), FLT_EPS)));
    deviceDepth = ComputeNormalizedDeviceCoordinatesWithZ(positionWS, UNITY_MATRIX_VP).z;
    bool killRay = deviceDepth == UNITY_RAW_FAR_CLIP_VALUE;

    // Ref. #1: Michal Drobot - Quadtree Displacement Mapping with Height Blending.
    // Ref. #2: Yasin Uludag  - Hi-Z Screen-Space Cone-Traced Reflections.
    // Ref. #3: Jean-Philippe Grenier - Notes On Screen Space HIZ Tracing.
    // Warning: virtually all of the code below assumes reverse Z.

    // We start tracing from the center of the current pixel, and do so up to the far plane.
    float3 rayOrigin = float3(coordSS + 0.5, deviceDepth);

    float3 reflPosWS = positionWS + R;
    float3 reflPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(reflPosWS, UNITY_MATRIX_VP); // Jittered
    float3 reflPosSS = float3(reflPosNDC.xy * _SsrTraceScreenSize.xy, reflPosNDC.z);
    float3 rayDir = reflPosSS - rayOrigin;
    float3 rcpRayDir = rcp(rayDir);
    int2 rayStep = int2(rcpRayDir.x >= 0 ? 1 : 0,
                        rcpRayDir.y >= 0 ? 1 : 0);
    float3 raySign = float3(rcpRayDir.x >= 0 ? 1 : -1,
                            rcpRayDir.y >= 0 ? 1 : -1,
                            rcpRayDir.z >= 0 ? 1 : -1);
    bool rayTowardsEye = rcpRayDir.z >= 0;

    // Note that we don't need to store or read the perceptualRoughness value
    // if we mark stencil during the G-Buffer pass with pixels which should receive SSR,
    // and sample the color pyramid during the lighting pass.
    killRay = killRay || (reflPosSS.z <= 0);
    killRay = killRay || (dot(N, V) <= 0);
    #ifndef SSR_TRACE_TOWARDS_EYE
    killRay = killRay || rayTowardsEye;
    #endif

    if (killRay)
    {
        return;
    }

    // Extend and clip the end point to the frustum.
    float tMax;
    {
        // Shrink the frustum by half a texel for efficiency reasons.
        const float halfTexel = 0.5;

        float3 bounds;
        bounds.x = (rcpRayDir.x >= 0) ? _SsrTraceScreenSize.x - halfTexel : halfTexel;
        bounds.y = (rcpRayDir.y >= 0) ? _SsrTraceScreenSize.y - halfTexel : halfTexel;
        // If we do not want to intersect the skybox, it is more efficient to not trace too far.
        float maxDepth = (_SsrReflectsSky != 0) ? -0.00000024 : 0.00000024; // 2^-22
        bounds.z = (rcpRayDir.z >= 0) ? 1 : maxDepth;

        float3 dist = bounds * rcpRayDir - (rayOrigin * rcpRayDir);
        tMax = Min3(dist.x, dist.y, dist.z);
    }

    // Clamp the MIP level to give the compiler more information to optimize.
    const int maxMipLevel = min(_SsrDepthPyramidMaxMip, 14);

    // Start ray marching from the next texel to avoid self-intersections.
    float t;
    {
        // 'rayOrigin' is the exact texel center.
        float2 dist = abs(0.5 * rcpRayDir.xy);
        t = min(dist.x, dist.y);
    }

    float3 rayPos;

    int mipLevel = 0;
    int iterCount = 0;
    bool hit = false;
    bool miss = false;
    bool belowMip0 = false; // This value is set prior to entering the cell


    while (!(hit || miss) && (t <= tMax) && (iterCount < _SsrIterLimit))
    {
        rayPos = rayOrigin + t * rayDir;

        // Ray position often ends up on the edge. To determine (and look up) the right cell,
        // we need to bias the position by a small epsilon in the direction of the ray.
        float2 sgnEdgeDist = round(rayPos.xy) - rayPos.xy;
        float2 satEdgeDist = clamp(raySign.xy * sgnEdgeDist + SSR_TRACE_EPS, 0, SSR_TRACE_EPS);
        rayPos.xy += raySign.xy * satEdgeDist;

        int2 mipCoord = (int2)rayPos.xy >> mipLevel;
        // Bounds define 4 faces of a cube:
        // 2 walls in front of the ray, and a floor and a base below it.
        float4 bounds;

        bounds.xy = (mipCoord + rayStep);
        bounds.z = LOAD_TEXTURE2D_X_LOD(_CameraDepthPyramidTexture, mipCoord, mipLevel).r;

        // We define the depth of the base as the depth value as:
        // b = DeviceDepth((1 + thickness) * LinearDepth(d))
        // b = ((f - n) * d + n * (1 - (1 + thickness))) / ((f - n) * (1 + thickness))
        // b = ((f - n) * d - n * thickness) / ((f - n) * (1 + thickness))
        // b = d / (1 + thickness) - n / (f - n) * (thickness / (1 + thickness))
        // b = d * k_s + k_b
        bounds.w = bounds.z * _SsrThicknessScale + _SsrThicknessBias;

        float4 dist = bounds * rcpRayDir.xyzz - (rayOrigin.xyzz * rcpRayDir.xyzz);
        float distWall = min(dist.x, dist.y);
        float distFloor = dist.z;
        float distBase = dist.w;

        // Note: 'rayPos' given by 't' can correspond to one of several depth values:
        // - above or exactly on the floor
        // - inside the floor (between the floor and the base)
        // - below the base
        #if 0
        bool belowFloor  = (raySign.z * (t - distFloor)) <  0;
        bool aboveBase   = (raySign.z * (t - distBase )) >= 0;
        #else
        bool belowFloor = rayPos.z < bounds.z;
        bool aboveBase = rayPos.z >= bounds.w;
        #endif
        bool insideFloor = belowFloor && aboveBase;
        bool hitFloor = (t <= distFloor) && (distFloor <= distWall);

        // Game rules:
        // * if the closest intersection is with the wall of the cell, switch to the coarser MIP, and advance the ray.
        // * if the closest intersection is with the heightmap below,  switch to the finer   MIP, and advance the ray.
        // * if the closest intersection is with the heightmap above,  switch to the finer   MIP, and do NOT advance the ray.
        // Victory conditions:
        // * See below. Do NOT reorder the statements!

        #ifdef SSR_TRACE_BEHIND_OBJECTS
        miss = belowMip0 && insideFloor;
        #else
        miss      = belowMip0;
        #endif
        hit = (mipLevel == 0) && (hitFloor || insideFloor);
        belowMip0 = (mipLevel == 0) && belowFloor;

        // 'distFloor' can be smaller than the current distance 't'.
        // We can also safely ignore 'distBase'.
        // If we hit the floor, it's always safe to jump there.
        // If we are at (mipLevel != 0) and we are below the floor, we should not move.
        t = hitFloor ? distFloor : (((mipLevel != 0) && belowFloor) ? t : distWall);
        rayPos.z = bounds.z; // Retain the depth of the potential intersection

        // Warning: both rays towards the eye, and tracing behind objects has linear
        // rather than logarithmic complexity! This is due to the fact that we only store
        // the maximum value of depth, and not the min-max.
        mipLevel += (hitFloor || belowFloor || rayTowardsEye) ? -1 : 1;
        mipLevel = clamp(mipLevel, 0, maxMipLevel);

        // mipLevel = 0;

        iterCount++;
    }

    // Treat intersections with the sky as misses.
    miss = miss || ((_SsrReflectsSky == 0) && (rayPos.z == 0));
    hit = hit && !miss;

    float hitOpacity = 0.0;
    if (hit)
    {
        // Note that we are using 'rayPos' from the penultimate iteration, rather than
        // recompute it using the last value of 't', which would result in an overshoot.
        // It also needs to be precisely at the center of the pixel to avoid artifacts.
        float2 hitCoordSS = floor(rayPos.xy);
        float2 hitScreenUV = hitCoordSS * _SsrTraceScreenSize.zw + (0.5 * _SsrTraceScreenSize.zw);

        float hitDeviceZ = LOAD_TEXTURE2D_X(_CameraDepthTexture, hitCoordSS).r;
        float3 hitPosWS = ComputeWorldSpacePosition(hitScreenUV, hitDeviceZ, UNITY_MATRIX_I_VP);
        float hitDistance = length(hitPosWS - originPosWS);
        _SSRRayInfoTexture[coordSS] = float3(max(ConeAngle, HALF_MIN), 1 / hitDistance, 0);

        float4 hitColorOpacity = LoadUVAndSampleRadianceFromPrevColorPyramidWithOpacity(hitScreenUV);
        _RayHitColorTexture[coordSS] = hitColorOpacity;

        hitOpacity = hitColorOpacity.a;
    }


    if (_SsrMixWithRayTracing == 0 && hitOpacity < 1.0)
    {
        float reflectionHierarchyWeight = hitOpacity;
        float3 reflectColor = _RayHitColorTexture[coordSS].xyz * _RayHitColorTexture[coordSS].w;
        float3 reflectDirWS = reflect(-V, N);
        // Evaluate Environment probes
        {
            PositionInputs posInput = GetPositionInput(coordSS.xy, _ScreenSize.zw,
                                                       LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS.xy).r,
                                                       UNITY_MATRIX_I_VP, UNITY_MATRIX_V, uint2(0, 0));
            float3 envReflection = SampleSkyEnvironment(reflectDirWS,  perceptualRoughness);
            reflectColor += envReflection;
        }

        // // Evaluate SkyEnvironment
        // if (reflectionHierarchyWeight < 1.0)
        // {
        //     float weight = 1.0;
        //     UpdateLightingHierarchyWeights(reflectionHierarchyWeight, weight);
        //     float3 skyReflection = SampleSkyEnvironment(reflectDirWS, perceptualRoughness);
        //     reflectColor += skyReflection * weight;
        // }

        _RayHitColorTexture[coordSS] = float4(reflectColor, 0);
        _SSRRayInfoTexture[coordSS] = float3(max(0, HALF_MIN), 1 / 5000.0, 0);
    }
}


// #elif defined(SSR_RESOLVE)
//
// groupshared float4  localRadianceDistance[256];
// groupshared float4       localNormalDepth[256];
//
// struct CoordData {
//     float3  radiance;
//     float   hitDistance;
//     float3  normal;
//     float   depth;
// };
//
// CoordData LoadFromGroupSharedMemory(uint2 gThreadId)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     float4 encodedRadianceVariance = localRadianceDistance[localID];
//     float4 encodedNormalDepth           = localNormalDepth[localID];
//
//     CoordData neighborSample = (CoordData) 0;
//     neighborSample.radiance = encodedRadianceVariance.xyz;
//     neighborSample.hitDistance = encodedRadianceVariance.w;
//     neighborSample.normal = encodedNormalDepth.xyz;
//     neighborSample.depth = encodedNormalDepth.w;
//     
//     return neighborSample;
// }
//
// void StoreInGroupSharedMemory(uint2 gThreadId, CoordData inData)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     localRadianceDistance[localID] = float4(inData.radiance.xyz, inData.hitDistance);
//     localNormalDepth[localID] = float4(inData.normal.xyz, inData.depth);
// }
//
// float4 LoadFromGroupSharedMemoryAvgRadiance(uint2 gThreadId)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     return localRadianceDistance[localID].xyzw;
// }
//
// void StoreInGroupSharedMemoryAvgRadiance(uint2 gThreadId, float4 radianceAndWeight)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     localRadianceDistance[localID] = radianceAndWeight.xyzw;
// }
//
//
// void ResolveLoadCoordData(uint2 coordSS, float4 screenSize, out float perceptualRoughness, out CoordData outData)
// {
//     float3 currColor = _RayHitColorTexture[coordSS].rgb;
//     outData.radiance = currColor;
//     outData.hitDistance = 1 / max(_SSRRayInfoTexture[coordSS].y, FLT_EPS);
//
//     LoadNormalAndPerceptualRoughness(coordSS, outData.normal, perceptualRoughness);
//
//     outData.depth = LinearEyeDepth(LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r, _ZBufferParams);
// }
//
// void InitializeGroupSharedMemory(uint2 dThreadId, uint2 gThreadId)
// {
//     uint2 offset[4] = {uint2(0, 0), uint2(8, 0), uint2(0, 8), uint2(8, 8)};
//
//     dThreadId -= 4;
//
//     float perceptualRoughness = 0;
//     CoordData coordData[4];
//     for (int i = 0; i < 4; i++)
//     {
//         ResolveLoadCoordData(dThreadId + offset[i], _ScreenSize, perceptualRoughness, coordData[i]);
//     }
//
//     for (int j = 0; j < 4; j++)
//     {
//         StoreInGroupSharedMemory(gThreadId + offset[j], coordData[j]);
//     }
// }
//
// // First 15 numbers of Halton(2,3) streteched to [-3,3]. Skipping the center, as we already have that in center_radiance and center_variance.
// static const int kResloveSampleCount = 15;
// static const int2 kResloveOffsets3x3[15] =
// {
//     int2( 0,  1),  
//     int2(-2,  1),  
//     int2( 2, -3), 
//     int2(-3,  0),  
//     int2( 1,  2), 
//     int2(-1, -2), 
//     int2( 3,  0), 
//     int2(-3,  3),
//     int2( 0, -3), 
//     int2(-1, -1), 
//     int2( 2,  1),  
//     int2(-2, -2), 
//     int2( 1,  0), 
//     int2( 0,  2),   
//     int2( 3, -1)
// };
//
// float ResloveGetEdegStoppingNormalWeight(float3 normal1, float3 normal2)
// {
//     return pow(max(dot(normal1, normal2), 0.0f), 512.0f);
// }
//
// float ResloveGetEdgeStoppingDepthWeight(float centerDepth, float neighDepth)
// {
//     return exp(-abs(centerDepth - neighDepth) * centerDepth * 4.0);
// }
//
// float ResloveGetRadianceWeight(float3 radiance1, float3 radiance2)
// {
//     return max(0.01, exp(-length(radiance1 - radiance2)));
// }
//
// [numthreads(8, 8, 1)]
// void ScreenSpaceReflectionsResolve(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint groupId : SV_GroupID)
// {
//     uint2 coordSS;
//     InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);
//
//     uint2 coordGroup = groupThreadId.xy;
//
//     float perceptualRoughness;
//     CoordData center;
//     float3 N;
//
//     LoadNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
//
//     InitializeGroupSharedMemory(coordSS, coordGroup);
//     GroupMemoryBarrierWithGroupSync();
//
//     coordGroup += 4;
//     center = LoadFromGroupSharedMemory(coordGroup);
//
//     float3 radiance = center.radiance;
//     float variance = 0.0f;
//     if (NEED_RAYTRACED_REFLECTIONS(perceptualRoughness))
//     {
//         float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);
//         float  centerDeviceZ = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
//         float3 centerPosWS = ComputeWorldSpacePosition(screenUV, centerDeviceZ, UNITY_MATRIX_I_VP);
//         float3 V = GetWorldSpaceNormalizeViewDir(centerPosWS);
//         
//         float closestHitDistance = center.hitDistance;
//
//         float weightSum = 0.0f;
//         float mean = 0.0f;
//         float varianceSum = 0.0f;
//         float3 radianceSum = 0.0f;
//
//         if (IS_MIRROR_REFLECTIONS(perceptualRoughness))
//         {
//             weightSum = 1.0f;
//             radianceSum = center.radiance;
//         }
//         else
//         {
//             float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
//             roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);
//             float radiusScale = lerp(0.0f, 1.0f, saturate(roughness * 32));
//             float rayDistScale = lerp(0.0f, 1.0f, saturate(center.hitDistance * 0.5));
//             
//             for (int i = 0; i < kResloveSampleCount; i++)
//             {
//                 uint2 neighCoordSS = coordGroup + radiusScale * rayDistScale * kResloveOffsets3x3[i];
//
//                 CoordData neighData = LoadFromGroupSharedMemory(neighCoordSS);
//
//                 float weight = 1;
//                 weight *= ResloveGetEdegStoppingNormalWeight(center.normal, neighData.normal);
//                 weight *= ResloveGetEdgeStoppingDepthWeight(center.depth, neighData.depth);
//                 weight *= ResloveGetRadianceWeight(center.radiance, neighData.radiance);
//
//
//                 if (weight > .001f)
//                 {
//                     closestHitDistance = min(closestHitDistance, neighData.hitDistance);
//                     IncreaseVariance(weight, Luminance(neighData.radiance), weightSum, mean, varianceSum);
//                     radianceSum += weight * neighData.radiance;
//                 }
//             }
//         }
//         
//
//
//         if (weightSum > 0.0f)
//         {
//             radianceSum /= weightSum;
//             varianceSum /= weightSum;
//             variance = varianceSum;
//             radiance = radianceSum;
//             _SSRAccumTexture[coordSS] = float4(radianceSum, varianceSum);
//
//
//             float3 virtualPosWS = centerPosWS - V * closestHitDistance;
//             float3 virtualPosNDC = ComputeNormalizedDeviceCoordinatesWithZ(virtualPosWS, UNITY_MATRIX_VP);
//             float3 rayInfo = _SSRRayInfoTexture[coordSS];
//             _SSRRayInfoTexture[coordSS] = float3(rayInfo.x, rayInfo.y, max(virtualPosNDC.z, 0));
//         }
//     }
//
//
//     GroupMemoryBarrierWithGroupSync();
//     // Average radiance
//     {
//         coordGroup -= 4;
//         float weight = 1;
//
//         if (AnyIsInf(radiance) || AnyIsNaN(radiance) || (weight < 0.001))
//         {
//             weight = 0.0f;
//         }
//         radiance *= weight;
//         StoreInGroupSharedMemoryAvgRadiance(coordGroup, float4(radiance, weight));
//         GroupMemoryBarrierWithGroupSync();
//
//         for (uint i = 2; i <= 8; i *= 2)
//         {
//             uint ox = coordGroup.x * i;
//             uint oy = coordGroup.y * i;
//             uint ix = coordGroup.x * i + i / 2;
//             uint iy = coordGroup.y * i + i / 2;
//             if (ix < 8 && iy < 8)
//             {
//                 float4 radianceWeight00 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ox, oy));
//                 float4 radianceWeight10 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ox, iy));
//                 float4 radianceWeight01 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ix, oy));
//                 float4 radianceWeight11 = LoadFromGroupSharedMemoryAvgRadiance(uint2(ix, iy));
//                 float4 sum = radianceWeight00 + radianceWeight10 + radianceWeight01 + radianceWeight11;
//                 StoreInGroupSharedMemoryAvgRadiance(uint2(ox, oy), sum);
//             }
//             GroupMemoryBarrierWithGroupSync();
//         }
//
//         if ((coordGroup.x == 0) && (coordGroup.y == 0))
//         {
//             float4 sum = LoadFromGroupSharedMemoryAvgRadiance(uint2(0, 0));
//             sum.xyz /= max(sum.w, 0.001);
//             _SSRAvgRadianceTexture[coordSS / 8] = sum.xyz;
//         }
//     }
//
// }
//
//
//
// #elif defined(SSR_ACCUMULATE)
//
//
// #define _MaxFramesAccumulated 32
// #define VARIANCE_REDUCTION_LERP(radiance, avgRadiance, variance) \
//         (lerp(radiance, avgRadiance, saturate(variance * 5)))
//
// groupshared float4 localRadianceVariance[256];
//
// struct CoordData {
//     float3  radiance;
//     float   variance;
// };
//
// CoordData LoadFromGroupSharedMemory(uint2 gThreadId)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     float4 encodedRadianceVariance = localRadianceVariance[localID];
//
//     CoordData neighborSample = (CoordData) 0;
//     neighborSample.radiance = encodedRadianceVariance.xyz;
//     neighborSample.variance = encodedRadianceVariance.w;
//     
//     return neighborSample;
// }
//
// void StoreInGroupSharedMemory(uint2 gThreadId, CoordData inData)
// {
//     uint localID = gThreadId.x + 16 * gThreadId.y;
//     localRadianceVariance[localID] = float4(inData.radiance.xyz, inData.variance);
// }
//
// void ResolveLoadCoordData(uint2 coordSS, out CoordData outData)
// {
//     float4 rv = _SSRAccumTexture[coordSS];
//     outData.radiance = rv.xyz;
//     outData.variance = rv.w;
// }
//
// void InitializeGroupSharedMemory(uint2 dThreadId, uint2 gThreadId)
// {
//     uint2 offset[4] = {uint2(0, 0), uint2(8, 0), uint2(0, 8), uint2(8, 8)};
//
//     dThreadId -= 4;
//
//     CoordData coordData[4];
//     for (int i = 0; i < 4; i++)
//     {
//         ResolveLoadCoordData(dThreadId + offset[i], coordData[i]);
//     }
//
//     for (int j = 0; j < 4; j++)
//     {
//         StoreInGroupSharedMemory(gThreadId + offset[j], coordData[j]);
//     }
// }
//
// struct FNeighborStatistics
// {
//     float3 mean;
//     float3 variance;
//     float3 stdDev;
//     float3 minVal;
//     float3 maxVal;
// };
//
// // Note: corners need to be first for GetNeighborStatistics
// static const int2 kOffsets3x3[8] =
// {
// 	int2(-1, -1),
// 	int2( 1, -1),
// 	int2(-1,  1),
// 	int2( 1,  1),
// 	int2( 0, -1),
// 	int2(-1,  0),
// 	int2( 1,  0),
// 	int2( 0,  1),
// };
// FNeighborStatistics GetNeighborStatistics(
//     uint2 coordGroup, 
//     uint2 MinScreenCoord, 
//     uint2 MaxScreenCoord,
//     float3 centerLighting,
//     float3 avgRadiance)
// {
//     FNeighborStatistics result = (FNeighborStatistics)0;
//
//     int count = 1;
//     float3 M1 = centerLighting;
//     float3 M2 = (float3)0;
//
//     result.minVal = centerLighting;
//     result.maxVal = centerLighting;
//
//     for(uint neighborId = 0; neighborId < 8; neighborId++)
//     {
//         int2 offset = kOffsets3x3[neighborId];
//         uint2 neighCoordGroup = coordGroup + offset;
//         neighCoordGroup = clamp(neighCoordGroup, MinScreenCoord, MaxScreenCoord);
//         
//         CoordData neighData;
//         neighData = LoadFromGroupSharedMemory(neighCoordGroup);
//         neighData.radiance = VARIANCE_REDUCTION_LERP(neighData.radiance, avgRadiance, neighData.variance);
//         {
//             result.minVal = min(result.minVal, neighData.radiance);
//             result.maxVal = max(result.maxVal, neighData.radiance);
//
//             // Welford's online algorithm for variance.
//             // More numerically stable than accumulating squares.
//             // https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
//             count += 1;
//             float3 delta1 = neighData.radiance - M1;
//             M1 += delta1 / count;
//             float3 delta2 = neighData.radiance - M1;
//             M2 += delta1 * delta2;
//         }
//     }
//
//     result.mean = M1;
//     result.variance = M2 / (count - 1 + FLT_EPS);
//     result.stdDev = sqrt(result.variance);
//
//     return result;
// }
//
//
// struct FBilinear
// {
//     float2 origin;
//     float2 weights;
// };
//
// FBilinear GetBilinearFilter(float2 uv, float2 textureSize)
// {
//     FBilinear result;
//     result.origin = floor(uv * textureSize - 0.5f);
//     result.weights = frac(uv * textureSize - 0.5f);
//     return result;
// }
//
//
// struct FGatherUV
// {
//     float2 uv00;
//     float2 uv10;
//     float2 uv11;
//     float2 uv01;
// };
//
// FGatherUV GetGatherUV(FBilinear In, float2 texelSize)
// {
//     FGatherUV o;
//     o.uv00 = (In.origin + .5f) * texelSize;
//     o.uv10 = o.uv00 + float2(texelSize.x, 0);
//     o.uv01 = o.uv00 + float2(0, texelSize.y);
//     o.uv11 = o.uv00 + texelSize;
//     return o;
// }
//
// float4 GetBilinearCustomWeights(FBilinear F, float4 CustomWeights)
// {
//     float4 weights;
//     weights.x = (1.0f - F.weights.x) * (1.0f - F.weights.y);
//     weights.y = F.weights.x * (1.0f - F.weights.y);
//     weights.z = (1.0f - F.weights.x) * F.weights.y;
//     weights.w = F.weights.x * F.weights.y;
//     return weights * CustomWeights;
// }
//
// float3 WeightedAverage(float3 V00, float3 V10,  float3 V01,  float3 V11, float4 weights)
// {
//     float3 result = V00 * weights.x + V10 * weights.y + V01 * weights.z + V11 * weights.w;
//     return result / max(dot(weights, 1), 0.00001f);
// }
//
// float WeightedAverage(float4 V, float4 weights)
// {    
//     return dot(V, weights) / max(dot(weights, 1), .00001f);
// }
//
// struct FSpecularIndirectHistory
// {
//     float3 specularIndirect;
//     float4 weights;
// };
//
// // Fetch the specular indirect history
// // * Returns the filtered specular indirect value (average only valid history sample
// // * Returns the weights of each indirect samples (valid/invalid)
// FSpecularIndirectHistory FetchHistory(TEXTURE2D_X(historyTexture), FBilinear inBilinear, uint InBSDFIndex, float4 screenSize, float4 inWeights = float4(1,1,1,1))
// {
//     FSpecularIndirectHistory o;
//     o.weights = GetBilinearCustomWeights(inBilinear, inWeights);
//     FGatherUV InHistoryBilinear = GetGatherUV(inBilinear, screenSize.zw);
//
//     float4 historySpecularIndirect00 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv00, 0).xyzw;
//     float4 historySpecularIndirect10 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv10, 0).xyzw;
//     float4 historySpecularIndirect01 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv01, 0).xyzw;
//     float4 historySpecularIndirect11 = SAMPLE_TEXTURE2D_X_LOD(historyTexture, ssr_point_clamp_sampler, InHistoryBilinear.uv11, 0).xyzw;
//
//     o.weights.x *= historySpecularIndirect00.w > 0 ? 1.0f : 0.0f;
//     o.weights.y *= historySpecularIndirect10.w > 0 ? 1.0f : 0.0f;
//     o.weights.z *= historySpecularIndirect01.w > 0 ? 1.0f : 0.0f;
//     o.weights.w *= historySpecularIndirect11.w > 0 ? 1.0f : 0.0f;
//
//     o.specularIndirect = WeightedAverage(historySpecularIndirect00.xyz, historySpecularIndirect10.xyz, historySpecularIndirect01.xyz, historySpecularIndirect11.xyz, o.weights);
//     return o;
// }
//
// [numthreads(8, 8, 1)]
// void ScreenSpaceReflectionsAccumulate(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint groupId : SV_GroupID)
// {
//     uint2 coordSS;
//     InitializeDispatchThreadIdFromTileList(groupId, groupThreadId, coordSS);
//     // uint2 coordSS = dispatchThreadId.xy;
//
//     uint2 coordGroup = groupThreadId.xy;
//     float2 screenUV = TransformCoordSSToScreenUV(coordSS, _ScreenSize);
//
//     float3 N;
//     float perceptualRoughness;
//     LoadNormalAndPerceptualRoughness(coordSS, N, perceptualRoughness);
//
//     CoordData center;
//     InitializeGroupSharedMemory(coordSS, coordGroup);
//     GroupMemoryBarrierWithGroupSync();
//
//     coordGroup += 4;
//     center = LoadFromGroupSharedMemory(coordGroup);
//     
//     
//     if (NEED_RAYTRACED_REFLECTIONS(perceptualRoughness))
//     {
//         // Compute the actual roughness
//         float roughness = PerceptualRoughnessToRoughness(perceptualRoughness);
//         roughness = clamp(roughness, MIN_GGX_ROUGHNESS, MAX_GGX_ROUGHNESS);
//         float roughnessReductionFactor = 1 - exp(-roughness * 100.0f);
//
//         float3 avgRadiance = SAMPLE_TEXTURE2D_X_LOD(_SSRAvgRadianceTexture, ssr_bilinear_clamp_sampler, screenUV, 0).xyz;
//
//         float3 currColor = VARIANCE_REDUCTION_LERP(center.radiance, avgRadiance, center.variance);
//         float reflectionHitDeviceZ = _SSRRayInfoTexture[coordSS].z;
//         float deviceDepth = LOAD_TEXTURE2D_X(_CameraDepthTexture, coordSS).r;
//         float2 motionVector = LoadMotionVectorOffset(coordSS);
//
//         float3 prevScreenPosFromVirtualHit = GetHistoryScreenPos(screenUV, deviceDepth, reflectionHitDeviceZ, motionVector, _SSR_MATRIX_CLIP_TO_PREV_CLIP);
//         float3 prevScreenPosFromSceneDepth = GetHistoryScreenPos(screenUV, deviceDepth, deviceDepth, motionVector, _SSR_MATRIX_CLIP_TO_PREV_CLIP);
//
//         // HistoryFrameTexture (_SsrAccumPrev and _SSRPrevNumFramesAccumTexture)
//         // CoordSS may not coverage RT completely, screen uv may lower than 1, when viewport changed.
//         // This situation is similar to ColorPyramid.
//         prevScreenPosFromVirtualHit.xy *= _ColorPyramidUvScaleAndLimitPrevFrame.xy;
//         prevScreenPosFromSceneDepth.xy *= _ColorPyramidUvScaleAndLimitPrevFrame.xy;
//
//         FBilinear bilinearVirtualHit = GetBilinearFilter(prevScreenPosFromVirtualHit.xy, _HistoryFrameRTSize.xy);
//         FBilinear bilinearSceneDepth = GetBilinearFilter(prevScreenPosFromSceneDepth.xy, _HistoryFrameRTSize.xy);
//
//         FSpecularIndirectHistory historyFromVirtualHit = FetchHistory(_SsrAccumPrev, bilinearVirtualHit, 0, _HistoryFrameRTSize.xyzw);
//         FSpecularIndirectHistory historyFromSceneDepth = FetchHistory(_SsrAccumPrev, bilinearSceneDepth, 0, _HistoryFrameRTSize.xyzw);
//
//         FNeighborStatistics neighborhood = GetNeighborStatistics(coordGroup, uint2(0,0), _HistoryFrameRTSize.xy, currColor, avgRadiance);
//
//
//         float InvalidHistoryErrorThreshold = 1e6;
//         float ErrorFromReflectHit = (any(prevScreenPosFromVirtualHit.xy >= 0) && any(prevScreenPosFromVirtualHit.xy <= 1)) ? abs(Luminance(historyFromVirtualHit.specularIndirect) - Luminance(neighborhood.mean)) : InvalidHistoryErrorThreshold;
//         float ErrorFromSceneDepth = (any(prevScreenPosFromSceneDepth.xy >= 0) && any(prevScreenPosFromSceneDepth.xy <= 1)) ? abs(Luminance(historyFromSceneDepth.specularIndirect) - Luminance(neighborhood.mean)) : InvalidHistoryErrorThreshold;
//
//         float3 historySpecularIndirect = ErrorFromReflectHit < ErrorFromSceneDepth
//             ? historyFromVirtualHit.specularIndirect 
//             : historyFromSceneDepth.specularIndirect;
//
//         neighborhood.stdDev = (neighborhood.stdDev + length(neighborhood.mean.xyz - avgRadiance)) * 1.0f;
//         neighborhood.mean = lerp(neighborhood.mean.xyz, avgRadiance, 0.2f * roughnessReductionFactor);
//         float3 historyClampMin = neighborhood.mean - neighborhood.stdDev;
//         float3 historyClampMax = neighborhood.mean + neighborhood.stdDev;
//
//         historyClampMin = max(0, historyClampMin);
//         historySpecularIndirect = clamp(historySpecularIndirect, neighborhood.minVal, historyClampMax);
//
//
//
//
//         float3 historyScreenUV = ErrorFromReflectHit < ErrorFromSceneDepth
//             ? prevScreenPosFromVirtualHit
//             : prevScreenPosFromSceneDepth;
//
//         // Sample neighbor frames num
//         float historyFramesNum = SAMPLE_TEXTURE2D_X_LOD(_SSRPrevNumFramesAccumTexture, ssr_point_clamp_sampler, historyScreenUV.xy, 0).x;
//         float maxSamplesNum = max(8.0f, _MaxFramesAccumulated * roughnessReductionFactor) * _SsrAccumulationAmount;
//         historyFramesNum *= maxSamplesNum;
//         historyFramesNum = min(historyFramesNum + 1.0f, maxSamplesNum);
//         float accumulatedFramesNum = (all(historyScreenUV.xy > 0) && all(historyScreenUV.xy < 1)) ? historyFramesNum : 0;
//
//         // Temporal accumulate
//         float temporalWeight = 1.0f / max(1.0f, accumulatedFramesNum);
//         float3 result = lerp(historySpecularIndirect, currColor, temporalWeight);
//
//         // Valid result
//         uint3 intCol = asuint(result.rgb);
//         bool  isPosFin = Max3(intCol.r, intCol.g, intCol.b) < 0x7F800000;
//         result.rgb = isPosFin ? result.rgb : 0;
//         bool bResultValid = all(result != 0);
//
//         // RoughnessFade
//         float roughnessFade = PerceptualRoughnessFade(perceptualRoughness, _SsrRoughnessFadeRcpLength, _SsrRoughnessFadeEndTimesRcpLength);
//
//         // Write texture
//         _SsrLightingTexture[coordSS] = float4(result, roughnessFade);
//         _SSRAccumTexture[coordSS] = float4(result, bResultValid);
//         _SSRNumFramesAccumTexture[coordSS] = accumulatedFramesNum / maxSamplesNum;
//     }
//
// }
//
// #endif

#undef MIN_GGX_ROUGHNESS
#undef MAX_GGX_ROUGHNESS
